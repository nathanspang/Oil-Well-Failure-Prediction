{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be utilizing Machine Learning in order to predict future mechanical failure of oil well machinery. I was given a trainining set of 60,000 rows of data taken from 107 sensors on different wells, as well as a target column with 0 for a surface related failure, or 1 for a below ground failure. The goal was use this training set to predict where a test set of wells would fail (surface or below ground). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I decided to fill the NaN cells with their given column's mean. Because of every column being a numberical sensor reading, I felt that this was a fair way to deal with NaN values, especially because the Kaggle competition did not allow for you to remove any rows when training the model, or predicting values. I would have ideally created a separate model where I only used non-NaN rows and compared model performance to see what would be the most accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('equip_failures_training_set.csv')\n",
    "test = pd.read_csv('equip_failures_test_set.csv')\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>sensor1_measure</th>\n",
       "      <th>sensor2_measure</th>\n",
       "      <th>sensor3_measure</th>\n",
       "      <th>sensor4_measure</th>\n",
       "      <th>sensor5_measure</th>\n",
       "      <th>sensor6_measure</th>\n",
       "      <th>sensor7_histogram_bin0</th>\n",
       "      <th>sensor7_histogram_bin1</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor105_histogram_bin2</th>\n",
       "      <th>sensor105_histogram_bin3</th>\n",
       "      <th>sensor105_histogram_bin4</th>\n",
       "      <th>sensor105_histogram_bin5</th>\n",
       "      <th>sensor105_histogram_bin6</th>\n",
       "      <th>sensor105_histogram_bin7</th>\n",
       "      <th>sensor105_histogram_bin8</th>\n",
       "      <th>sensor105_histogram_bin9</th>\n",
       "      <th>sensor106_measure</th>\n",
       "      <th>sensor107_measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76698</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33058</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>190620.639314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41040</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>60874</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  sensor1_measure  sensor2_measure  sensor3_measure  \\\n",
       "0   1       0            76698         0.713189     2.130706e+09   \n",
       "1   2       0            33058         0.713189     0.000000e+00   \n",
       "2   3       0            41040         0.713189     2.280000e+02   \n",
       "3   4       0               12         0.000000     7.000000e+01   \n",
       "4   5       0            60874         0.713189     1.368000e+03   \n",
       "\n",
       "   sensor4_measure  sensor5_measure  sensor6_measure  sensor7_histogram_bin0  \\\n",
       "0       280.000000              0.0              0.0                     0.0   \n",
       "1    190620.639314              0.0              0.0                     0.0   \n",
       "2       100.000000              0.0              0.0                     0.0   \n",
       "3        66.000000              0.0             10.0                     0.0   \n",
       "4       458.000000              0.0              0.0                     0.0   \n",
       "\n",
       "   sensor7_histogram_bin1  ...  sensor105_histogram_bin2  \\\n",
       "0                     0.0  ...                 1240520.0   \n",
       "1                     0.0  ...                  421400.0   \n",
       "2                     0.0  ...                  277378.0   \n",
       "3                     0.0  ...                     240.0   \n",
       "4                     0.0  ...                  622012.0   \n",
       "\n",
       "   sensor105_histogram_bin3  sensor105_histogram_bin4  \\\n",
       "0                  493384.0                  721044.0   \n",
       "1                  178064.0                  293306.0   \n",
       "2                  159812.0                  423992.0   \n",
       "3                      46.0                      58.0   \n",
       "4                  229790.0                  405298.0   \n",
       "\n",
       "   sensor105_histogram_bin5  sensor105_histogram_bin6  \\\n",
       "0                  469792.0                  339156.0   \n",
       "1                  245416.0                  133654.0   \n",
       "2                  409564.0                  320746.0   \n",
       "3                      44.0                      10.0   \n",
       "4                  347188.0                  286954.0   \n",
       "\n",
       "   sensor105_histogram_bin7  sensor105_histogram_bin8  \\\n",
       "0                  157956.0                   73224.0   \n",
       "1                   81140.0                   97576.0   \n",
       "2                  158022.0                   95128.0   \n",
       "3                       0.0                       0.0   \n",
       "4                  311560.0                  433954.0   \n",
       "\n",
       "   sensor105_histogram_bin9  sensor106_measure  sensor107_measure  \n",
       "0                       0.0                0.0                0.0  \n",
       "1                    1500.0                0.0                0.0  \n",
       "2                     514.0                0.0                0.0  \n",
       "3                       0.0                4.0               32.0  \n",
       "4                    1218.0                0.0                0.0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, 100 of the sensors take a single measurement, while 7 of the sensors (sensors 7, 24, 25, 26, 64, 69 and 104) each have 10 values taken in equal time intervals. I decided to try 3 models: one created by using all of the values for each of these sensors, one using the mean of the 10 values, and one using the median of the 10 values. This way, I have more opportunity to find the most accurate values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am first going to use the data set as is with all 10 values for each of the histogram sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[train.columns[1]]\n",
    "X_train = train[train.columns[2:]]\n",
    "X_test = test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to try all of these options with 4 classification algorithms (Logistic Regression, Decision Tree, Random Forest, and XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "y_pred = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.97678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.97464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.98857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.96517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the random forest model performed the best per the judging policy of the Kaggle competition. I going to run all of these models again but I am going to replace the 10 separate values for each of the histogramic sensors with one value of the mean of their values, and test with the same mean in the test set. I also decided to not use the XGBoost algorithm on the next two versions since it was substantially less accurate on the original data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to create a column for the mean of each of these sensors, and remove the 10 separate values from the data frame. I have chosen to hard code the column indices due to knowing which sensors were histogramic, but in the future I would develop a function to automate finding these sensors and calculating the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_7 = train.loc[:, train.columns[8]:train.columns[17]]\n",
    "train['sensor_7_mean'] = col_7.mean(axis=1)\n",
    "col_24 = train.loc[:, train.columns[34]:train.columns[43]]\n",
    "train['sensor_24_mean'] = col_24.mean(axis=1)\n",
    "col_25 = train.loc[:, train.columns[44]:train.columns[53]]\n",
    "train['sensor_25_mean'] = col_25.mean(axis=1)\n",
    "col_26 = train.loc[:, train.columns[54]:train.columns[63]]\n",
    "train['sensor_26_mean'] = col_26.mean(axis=1)\n",
    "col_64 = train.loc[:, train.columns[101]:train.columns[110]]\n",
    "train['sensor_64_mean'] = col_64.mean(axis=1)\n",
    "col_69 = train.loc[:, train.columns[115]:train.columns[124]]\n",
    "train['sensor_69_mean'] = col_69.mean(axis=1)\n",
    "col_105 = train.loc[:, train.columns[160]:train.columns[169]]\n",
    "train['sensor_105_mean'] = col_105.mean(axis=1)\n",
    "\n",
    "train.drop(col_7, axis=1, inplace=True)\n",
    "train.drop(col_24, axis=1, inplace=True)\n",
    "train.drop(col_25, axis=1, inplace=True)\n",
    "train.drop(col_26, axis=1, inplace=True)\n",
    "train.drop(col_64, axis=1, inplace=True)\n",
    "train.drop(col_69, axis=1, inplace=True)\n",
    "train.drop(col_105, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now create the new X and y train frames, do the same column calculation on the test set, and re run the models on this new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train.columns[2:]]\n",
    "y_train = train[train.columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_7_t = test.loc[:, test.columns[7]:test.columns[16]]\n",
    "test['sensor_7_mean'] = col_7_t.mean(axis=1)\n",
    "col_24_t = test.loc[:, test.columns[33]:test.columns[42]]\n",
    "test['sensor_24_mean'] = col_24_t.mean(axis=1)\n",
    "col_25_t = test.loc[:, test.columns[43]:test.columns[52]]\n",
    "test['sensor_25_mean'] = col_25_t.mean(axis=1)\n",
    "col_26_t = test.loc[:, test.columns[53]:test.columns[62]]\n",
    "test['sensor_26_mean'] = col_26_t.mean(axis=1)\n",
    "col_64_t = test.loc[:, test.columns[100]:test.columns[109]]\n",
    "test['sensor_64_mean'] = col_64_t.mean(axis=1)\n",
    "col_69_t = test.loc[:, test.columns[114]:test.columns[123]]\n",
    "test['sensor_69_mean'] = col_69_t.mean(axis=1)\n",
    "col_105_t = test.loc[:, test.columns[159]:test.columns[168]]\n",
    "test['sensor_105_mean'] = col_105_t.mean(axis=1)\n",
    "\n",
    "test.drop(col_7_t, axis=1, inplace=True)\n",
    "test.drop(col_24_t, axis=1, inplace=True)\n",
    "test.drop(col_25_t, axis=1, inplace=True)\n",
    "test.drop(col_26_t, axis=1, inplace=True)\n",
    "test.drop(col_64_t, axis=1, inplace=True)\n",
    "test.drop(col_69_t, axis=1, inplace=True)\n",
    "test.drop(col_105_t, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "y_pred = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.96839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.94642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.98330"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the models run with the mean of histogramic sensors were generally less accurate than the same algorithm run on the original data. The random forest algorithm was still the most accurate, but not as accurate as the previous random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now going to follow the same procedure, but using the median instead of the mean to see if this is any more accurate. I must first reload the original datasets to re-create the median columns from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('equip_failures_training_set.csv')\n",
    "test = pd.read_csv('equip_failures_test_set.csv')\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_7 = train.loc[:, train.columns[8]:train.columns[17]]\n",
    "train['sensor_7_mean'] = col_7.median(axis=1)\n",
    "col_24 = train.loc[:, train.columns[34]:train.columns[43]]\n",
    "train['sensor_24_mean'] = col_24.median(axis=1)\n",
    "col_25 = train.loc[:, train.columns[44]:train.columns[53]]\n",
    "train['sensor_25_mean'] = col_25.median(axis=1)\n",
    "col_26 = train.loc[:, train.columns[54]:train.columns[63]]\n",
    "train['sensor_26_mean'] = col_26.median(axis=1)\n",
    "col_64 = train.loc[:, train.columns[101]:train.columns[110]]\n",
    "train['sensor_64_mean'] = col_64.median(axis=1)\n",
    "col_69 = train.loc[:, train.columns[115]:train.columns[124]]\n",
    "train['sensor_69_mean'] = col_69.median(axis=1)\n",
    "col_105 = train.loc[:, train.columns[160]:train.columns[169]]\n",
    "train['sensor_105_mean'] = col_105.median(axis=1)\n",
    "\n",
    "train.drop(col_7, axis=1, inplace=True)\n",
    "train.drop(col_24, axis=1, inplace=True)\n",
    "train.drop(col_25, axis=1, inplace=True)\n",
    "train.drop(col_26, axis=1, inplace=True)\n",
    "train.drop(col_64, axis=1, inplace=True)\n",
    "train.drop(col_69, axis=1, inplace=True)\n",
    "train.drop(col_105, axis=1, inplace=True)\n",
    "\n",
    "X_train = train[train.columns[2:]]\n",
    "y_train = train[train.columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_7_t = test.loc[:, test.columns[7]:test.columns[16]]\n",
    "test['sensor_7_mean'] = col_7_t.median(axis=1)\n",
    "col_24_t = test.loc[:, test.columns[33]:test.columns[42]]\n",
    "test['sensor_24_mean'] = col_24_t.median(axis=1)\n",
    "col_25_t = test.loc[:, test.columns[43]:test.columns[52]]\n",
    "test['sensor_25_mean'] = col_25_t.median(axis=1)\n",
    "col_26_t = test.loc[:, test.columns[53]:test.columns[62]]\n",
    "test['sensor_26_mean'] = col_26_t.median(axis=1)\n",
    "col_64_t = test.loc[:, test.columns[100]:test.columns[109]]\n",
    "test['sensor_64_mean'] = col_64_t.median(axis=1)\n",
    "col_69_t = test.loc[:, test.columns[114]:test.columns[123]]\n",
    "test['sensor_69_mean'] = col_69_t.median(axis=1)\n",
    "col_105_t = test.loc[:, test.columns[159]:test.columns[168]]\n",
    "test['sensor_105_mean'] = col_105_t.median(axis=1)\n",
    "\n",
    "test.drop(col_7_t, axis=1, inplace=True)\n",
    "test.drop(col_24_t, axis=1, inplace=True)\n",
    "test.drop(col_25_t, axis=1, inplace=True)\n",
    "test.drop(col_26_t, axis=1, inplace=True)\n",
    "test.drop(col_64_t, axis=1, inplace=True)\n",
    "test.drop(col_69_t, axis=1, inplace=True)\n",
    "test.drop(col_105_t, axis=1, inplace=True)\n",
    "\n",
    "X_test = test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "y_pred = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.97160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.78223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested accuracy = 0.97946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the accuracies above, the median values did not improve the accuracy from the mean or the original data frame. The model combination that I found to be most accurate was using the Random Forest Algorithm on the original data set including all 10 of the sensor measurments for each of the 7 histogramic sensors. This model is a very effective way to predict whether the Oil Well could have a surface or below ground failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
